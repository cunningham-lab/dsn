% You should title the file with a .tex extension (hw1.tex, for example)
\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{wrapfig}
\usepackage{fancyhdr}
\usepackage{tikz-qtree}
\usepackage{tikz-qtree-compat}
\usepackage[normalem]{ulem}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{lineno}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}

\oddsidemargin0cm
\topmargin-2cm     %I recommend adding these three lines to increase the 
\textwidth16.5cm   %amount of usable space on the page (and save trees)
\textheight23.5cm  

\newcommand{\question}[2] {\vspace{.25in} \hrule\vspace{0.5em}
\noindent{\bf #1: #2} \vspace{0.5em}
\hrule \vspace{.10in}}
\renewcommand{\part}[1] {\vspace{.10in} {\bf (#1)}}
\linespread{1.5}

\newcommand{\myname}{Anonymous Authors}
\newcommand{\myhwnum}{12}

\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}
 
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%

\pagestyle{fancyplain}

\begin{document}
\medskip                        % Skip a "medium" amount of space
                                % (latex determines what medium is)
                                % Also try: \bigskip, \littleskip

\thispagestyle{plain}
{\Large Theories of neural computation are enhanced by the modern inference engine.} \\
Sean R. Bittner, Agostina Palmigiano, Alex T. Piet, Chunyu A. Duan, Francesca Mastrogiuseppe, Srdjan Ostojic, Carlos D. Brody, Kenneth D. Miller, and John P. Cunningham.

\linenumbers
\section{Abstract}
The cornerstone of theoretical neuroscience is the circuit model: a set of differential equations that capture a hypothesized neural mechanism of scientific importance.  At its best, such a model will give rise to an experimentally observed phenomenon -- whether behavioral or in terms of neural activity -- and thus can offer insight into neural computation.  The behavior of these circuits, like all models, critically depends on the choices of model parameters.  Indeed, the historical gold standard has been to analytically derive the relationship between model parameters and emergent properties of computation.  However, this enterprise quickly becomes infeasible as biologically realistic constraints are included into the model, resulting often in \emph{ad hoc} approaches to understanding the relationship between model and computation.  Here we advance cutting edge machine learning -- the use of deep learning for probabilistic inference -- to learn parameter distributions that capture a hypothesized property of computation.   Importantly, the techniques we introduce offer 
a rational and normative % looking for some adjectives... these kind of suck.
means to understand the implications of model parameter choices on scientific properties of interest.  To make these contributions concrete, we use these techniques to discover novel insights into network syncing in the stomatogastric ganglion, neuron-type input-responsivity in primary visual cortex, rapid task switching in superior colliculus, and approximate Bayesian inference in recurrent neural networks. More generally, this work points to a future where the gold standard of theoretical neuroscience will be the rule, not the exception, of modeling neural circuits. \\
%(150 word limit) we can ignore that for now up to about 50% \\

\section{Introduction}
Mathematical modeling has become a key part of modern neuroscience \cite{abbott2008theoretical}. A theory of neural computation describes a neural system with a set of equations (i.e. a model) motivated by the laws of nature and neurophysiological observations.  The key challenge for theorists is the description of how the model parameters govern the computational function of the neural system, which is characterized by mathematically defined features or ``emergent properties" of computation.  In idealized practice, theorists analytically derive how model parameters govern these emergent properties.  Historical examples of this gold standard of theory include derivations of memory capacity in associative neural networks  \cite{hopfield1984neurons}, chaos and autocorrelation timescales in random neural networks \cite{sompolinsky1988chaos}, and the paradoxical effect in E/I networks \cite{tsodyks1997paradoxical}.  Unfortunately, as biological realism is introduced into neural circuit models, theory through analytic derivation becomes infeasible. \\

In fact, neural circuit models are designed in the context of misaligned incentives.  Models are kept simplistic with unrealistic assumptions (e.g. symmetry, gaussianity) to facilitate analytic derivations.  On the other hand, complexity is introduced for biological relevance. In models, simplicity sacrifices biological realism for derivations, and complexity sacrifices derivations for biological realism. When biological realism is the focus of a study, standard practice is to examine simulated activity from the model \cite{gutierrez2013multiple} (cite a bunch here).  Visualization or regression is used to understand the model, however theorists strive for a more formalized understanding of these complex models. \\

Classically, statistical inference is a formalized way of describing the probabilistic relationship between observed data and model parameters.  However, statistical inference is impracticable in neural system models, because the likelihood functions are generally intractable.  Research in neural data analysis, which has enhanced our knowledge of a[kass], b[brown], c[paninski], d[jpcunni], e[pillow], focuses on the development of statistically inferable models for neural data sets, where such likelihood functions are tractable. Likelihood function intractability thus creates a gap between the models analyzed by theoreticians (motivated by laws of nature and physiology) and the probabilistic models developed by neural data scientists (constrained by tractability of inference) (Figure 1?).   Theoretical neuroscientists are careful about model creation, where neural data analysts are practical.  Neural data analysts are careful about inference of model parameters, where theoretical neuroscientists are practical.  This motivates the question: can we start doing \emph{careful} inference in \emph{careful} models? \\

Advancements in probabilistic machine learning have led to transformative changes in industrial applications like image processing (sparse cite), speech recognition (sparse cite), text classification (sparse cite), and more.  We call the generalizable components of this groundbreaking technology (deep learning, stochastic gradient descent, GPU parallelization, etc.) the ``modern inference engine." (Point to work from Cunningham/Paninski using modern inference engine for neuroscientific phenomenological models (PfLDS, BehaveNET)?) In this study, we use the modern inference engine to bypass the perceived intractability of statistical inference in realistic models of neural systems.  (Introduce SDNs?)  We demonstrate the widespread applicability of this approach by producing novel insights into network syncing in the stomatogastric ganglion (STG), neuron-type input-responsivity in primary visual cortex (V1), rapid task switching in superior colliculus (SC), and approximate Bayesian inference in recurrent neural networks (RNNs). \\

\section{Results}
\subsection{Degenerate solution networks}
\begin{itemize}
\item To translate progress in neural data analysis to theoretical neuro, need to key steps.
\begin{itemize}
\item 1. Need to learn parameter distributions of biologically realistic (not just phenom.) models.
\item 2. Must be able to condition on emergent properties of interest, not simply computationally convenient sufficient statistics of data sets.
\end{itemize}
\item Bayesian data scientists will say experimental data is all that matters.  
\item \textit{Transition}: This is untrue when working in a creative, exploratory modeling setting.
\end{itemize}

\textbf{Edgy contrarian point about theorists and data}
\begin{itemize}
\item Common misconception: theoreticians rarely attempt to directly reproduce experimental data. 
\item Instead, they work with (abstracted?) mathematical definitions of emergent properties.  
\end{itemize}

\textbf{DSNs}
\begin{itemize}
\item We introduce DSNs, which bridge methodology in these subfields of comp neuro.
\item  Combine ideas from MEFNs (cite Gabe) and LFVI (cite Dustin) to learn a deep probability distribution of theoretical model parameterizations $z$ that produce the emergent properties of interest $T(x)$ (see Appendix).  
\item Explain deep probability distributions.
\item DSNs are deep probability distributions of theoretical model parameters, which are optimized to be maximally random (maximum entropy) while producing the specified value of emergent properties:
\begin{equation}
\begin{split}
q_\theta^*(z) &= \argmax_{q_\theta \in Q} H(q_\theta(z)) \\
 &  \text{s.t.  } E_{z \sim q_\theta}\left[ E_{x\sim p(x \mid z)}\left[T(x)\right] \right] = \mu \\
 \end{split}
\end{equation}
\end{itemize}

\textbf{Worked example: STG}
\begin{itemize}
\item For example, consider the STG.
\item Explain this STG circuit, emergent property of interest.
\item  For our choices of STG as model and network syncing as emergent property, we use a DSN to learn a distribution on STG conductance parameters that produces network syncing.  
\item Emphasize utility of DSN using Hessian.
\item An equivalent conceptualization is that DSNs do Bayesian inference (see Appendix).
\item Punchline about DSNs and transition to V1.
\end{itemize}

\subsection{Exploratory analysis of a theoretical model}
Will focus on this once result finalized.  Have a lot of text to pull from.

\subsection{Identifying sufficient mechanisms of task learning}
Will focus on this once V1 and LRRNN finalized.  Have a lot of text to pull from.

\subsection{Conditioning on computation with interpretable models of RNNs}
Will focus on this once result finalized.  Have a lot of text to pull from.

\section{Discussion}
\begin{itemize}
\item Summarize the key methodlogical demonstrations from the results section.
\item Talk big picture: If we know we can't analytically derive these things, we need an alternative characterization.  Simulate and examine isn't cutting it.  We need to be leveraging the modern inference engine to gain this understanding.  Bayesian probability is the framework we should use for this formalism.
\item Expand on idea of posterior predictive checks / hypothesis testing / exploratory analyses of models themselves.  Give the whole, we don't even understand the models we're developing pitch.
\item Elaborate on idea of conditioning on flexibly defined statistics i.e. emergent properties. Emphasize how this is practical.  Link to sufficient statistics, esp. commonly used in phenom models like spike counts etc.
\item Summarize the respective strengths SNPE and DSN.
\item Link conditioning on task execution with work done today with RNNs.  Basically, we're training overparameterized models with regression, and get a distribution (we have no prob treatment of). Emphasize utility of low-dim interpretable parameterizations.
\item A paragraph on bridging large scale recordings with theory.
\end{itemize}

\bibliography{dsn}
\bibliographystyle{unsrt}

\end{document}


