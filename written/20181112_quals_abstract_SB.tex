% You should title the file with a .tex extension (hw1.tex, for example)
\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{tikz-qtree}
\usepackage{tikz-qtree-compat}
\usepackage[normalem]{ulem}
\usepackage{tikz}
\usepackage{graphicx}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}

\oddsidemargin0cm
\topmargin-2cm     %I recommend adding these three lines to increase the 
\textwidth16.5cm   %amount of usable space on the page (and save trees)
\textheight23.5cm  

\newcommand{\question}[2] {\vspace{.25in} \hrule\vspace{0.5em}
\noindent{\bf #1: #2} \vspace{0.5em}
\hrule \vspace{.10in}}
\renewcommand{\part}[1] {\vspace{.10in} {\bf (#1)}}

\newcommand{\myname}{Sean Bittner}
\newcommand{\myandrew}{srb2201@columbia.edu}
\newcommand{\myhwnum}{12}

\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}
 
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
 
\pagestyle{fancyplain}
\rhead{\fancyplain{}{\myname\\ \myandrew}}

\begin{document}

\medskip                        % Skip a "medium" amount of space
                                % (latex determines what medium is)
                                % Also try: \bigskip, \littleskip

\thispagestyle{plain}
\begin{center}                  % Center the following lines
{\Large Degenerate solution networks (DSNs) for theoretical neuroscience} \\
Sean Bittner \\
Novemeber 8, 2018 \\
\end{center}

Theoretical neuroscientists design and test mathematical models of neural activity, assessing a modelâ€™s quality by its ability to replicate experimental results. This is done with rapid turnover, where proposed models are frequently rejected and sometimes promoted when they accurately postdict experimental findings \cite{abbott2008theoretical}.  A challenge in this scientific paradigm is the indeterminacy of model parameterizations; different parameterizations of these models accurately reflect established experiments, but make disparate predictions about uncharacterized properties of neurobiological activity.  Oftentimes, the parameter space of these models is examined by extensive simulation.  When both data and a reliable posterior inference method are available, probability can be assigned to each parameterization based on data likelihood and some prior assumptions.  Even in these cases, it is unclear how the structure of the posterior distribution relies on the various properties of the data.  We propose a new machine learning methodology for learning probabilistic models of the full degenerate solution space of generative models given statistical descriptions of the model behavior.  The (Aim 1) development of degenerate solution networks (DSNs) will enable (Aim 2) characterization of learning algorithm biases, (Aim 3) behavioral model comparison, and (Aim 4) behavioral model revision.

\textbf{Aim 1: Develop DSNs and assess scalability on classes of models and behaviors.} \\
DSNs learn the full distribution of model parameterizations that yield a model behavior of interest.  Consider model parameterization $z$ and data $x$ generated from some generative model of interest with known sampling procedure, and likelihood $p(x \mid z)$, which may or may not be known (as is common for models in theoretical neuroscience). DSNs learn a distribution on parameters $z$, that yields a behavior of interest $\mathcal{B}_i: E_{z \sim q_\theta}\left[ E_{x\sim p(x \mid z)}\left[T_i(x)\right] \right] = \mu_i$.  Since the family of $p(z \mid \mathcal{B})$ is generally unknown, DSNs make deep generative flexible approximations $q_\theta(z)$ as in \cite{rezende2015variational}.  In deep generative models, a simple random variable $w \sim p_0$ is mapped deterministically via a function $f_\theta$ parameterized by a neural network to the support of the distribution of interest:
\begin{equation} 
z = f_{\theta}(w) 
\end{equation} 
 DSNs are trained by optimizing the deep generative parameters $\theta$ to find the optimal approximation $q_{\theta}^*$ within the deep generative variational family $Q$ to the full degenerate solution space of a generative model $p(x \mid z)$ for a given behavior $\mathcal{B}$.  This procedure is loosely equivalent to variational inference (VI) using a deep generative variational family with respect to the likelihood of the mean sufficient statistics rather than the data itself.  In most settings (especially those relevant to theoretical neuroscience) the likelihood of the behavior with respect to the model parameters $p(T(x) \mid z)$ is unknown or intractable, requiring an alternative to stochastic gradient variational bayes (SGVB) \cite{kingma2013auto} or black box variational inference (BBVI) \cite{ranganath2014black}. As long as the desired behavior of the model can be statistically characterized as some expectation of sufficient statistics that are differentiable with respect to the model parameters $z$ (and therefore the deep generative parameters $\theta$), we can run the corresponding augmented LaGrangian procedure for the constrained maximum entropy optimization \cite{loaiza2017maximum}.  This is done by optimizing the following objective for a behavior of interest:
\begin{equation}
\begin{split}
q_\theta^*(z) = & \argmax_{q_\theta \in Q} H(q_\theta(z)) \\
& \text{s.t.  } E_{z \sim q_\theta}\left[ E_{x\sim p(x \mid z)}\left[T(x)\right] \right] = \mu \\
\end{split}
\end{equation}
A convenient property of maximum entropy optimizations is their exponential family form solutions, which yield a convenient diagnostic for assessing global maximum convergence \cite{bittner2018learning}. The tractability of this optimization will be assessed using this diagnostic with regard to a mixture of factors: dimensionality of the parameter space, the complexity of the model, and the behavior of interest.


\textbf{Aim 2: Learn solution spaces of dynamic computations.} \\
Recurrent neural networks (RNNs) are often trained to execute computations in order to perform some experimental task with the intention of comparing the trained system's activity with that measured in the brain \cite{sussillo2014neural}.  Statements about the particular algorithm or computational strategy implemented by the RNN are often made by analyzing linearized dynamics around fixed points \cite{sussillo2013opening}.  There are a variety of methods used to train RNNs \cite{werbos1990backpropagation, sussillo2009generating, martens2011learning, depasquale2018full}, and how these learning methods bias the learned connectivities (and potentially the implemented algorithm) within the broader solution space remains poorly understood.  Relying on recent work describing the statistical properties of low-rank RNNs \cite{mastrogiuseppe2018linking}, we can train DSNs to learn maximally expansive low dimensional distributions of parameterizations of network connectivities that solve tasks such as noisy stimulus detection, context-dependent discrimination, and evidence integration.  To check for a particular bias in a training method, we can formulate a structure-indicating test statistic that captures this bias.  Then, the distribution of this test statistic over randomness in the training procedure can be compared to its distribution in the full solution space obtained with DSNs.

This will be our first use of DSNs to generate maximally random distributions of test statistics under a model with a particular behavioral specification.  One can think of DSNs as a tool to obtain full distributions of summary statistics of models given constraints on the model behavior.  Here, we will use DSNs to test whether some learning algorithms bias RNN connectivity within the broader solution space. 

\textbf{Aim 3: Behavioral model comparison.} \\
Bayesian statistical analyses allow us to make inferences about the rules that govern the data we have and will have, which is commonly framed as inductive reasoning.  As Gelman and Shalizi remind us \cite{gelman2013philosophy}, model checking procedures comparing test statistics of the data and posterior-predictive distribution facilitate model rejection through hypothetico-deductive reasoning.  Akin to the idea of model-checking in Bayesian statistics, with DSNs, we can compare full distributions of a test statistics of models $\mathcal{M}_{p,\mathcal{B}}$ indexed by generative model $p$ and produced behavior $\mathcal{B}$ to the same generative model producing different behaviors (compare $\mathcal{M}_{p,\mathcal{B}_1}$ to $\mathcal{M}_{p,\mathcal{B}_2}$), another model producing the same behavior (compare $\mathcal{M}_{p_1,\mathcal{B}}$ to $\mathcal{M}_{p_2,\mathcal{B}}$), and a different model producing a different behavior (compare $\mathcal{M}_{p_1,\mathcal{B}_1}$ to $\mathcal{M}_{p_2,\mathcal{B}_2}$).  Critically, none of the listed types of model comparisons directly relies on collected data as is typical in traditional statistical thinking.  While the behaviors we are interested in are likely motivated by data collected through experimentation, the data itself is unnecessary for executing a hypothesis test.  To demonstrate how powerful this methodology can be, we will use a single analysis facilitated by DSNs to make an affirmative statement about the relationship of noise robustness and tangling in RNNs, compared to several analyses which made a weaker statement in our previous work \cite{russo2018motor}.

\textbf{Aim 4: Behavioral model revision.} \\
Access to the full probabilistic degenerate solution space of a theoretical model that yields accurate postdictions can inform model revision in several ways.  Say we have behaviors $\mathcal{B}_1$ and $\mathcal{B}_2$ which are well established experimentally.  We have some model $p(x | z; \phi)$ with parameters $z$ and hyperparameters governing model selection $\phi$, which is capable of producing behaviors $\mathcal{B}_1$ and $\mathcal{B}_2$ independently.  We break down $\phi = \left[\phi_c, \phi_{nc} \right]$ into continuous and non-continuous sets of model-selection parameters, respectfully.  For example, $\phi_{nc}$ may govern some choice of model architecture.  If we learn a DSN for $\mathcal{M}_{p,\mathcal{B}_1}$ and find there is no support of $q_{\theta}^*(z)$ that yields $\mathcal{B}_2$, we effectively realize that our model is wrong.  Our first step for model revision can be to choose some subset of $\phi_{c,opt} \subseteq \phi_c$, and concatenate it to $z$ so that $\tilde{z} = [z, \phi_{c,opt}]$ with $\tilde{\phi} = \left[ \phi_{c,fixed}, \phi_{nc} \right]$, and learn a new DSN $\mathcal{M}_{\tilde{p}, \mathcal{B}_1}$ for generative model $\tilde{p}(x \mid \tilde{z}, \tilde{\phi})$.  Then, we can look for $\phi_{c,opt}$ that yield $\mathcal{B}_2$ indicating the necessary model revision.  Alternatively, insights from the probabilistic degenerate solution space can give theorists with specialty knowledge about $p(x | z; \phi)$ information on how to change $\phi$ in general.  We will demonstrate how probabilistic degenerate solution spaces of a V1 circuit model reproducing findings from \cite{dipoppa2018vision} can be used to prescribe actions for model revision.

\bibliography{dsn}
\bibliographystyle{unsrt}

\end{document}

