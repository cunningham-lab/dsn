\begin{thebibliography}{10}

\bibitem{abbott2008theoretical}
Larry~F Abbott.
\newblock Theoretical neuroscience rising.
\newblock {\em Neuron}, 60(3):489--495, 2008.

\bibitem{rezende2015variational}
Danilo~Jimenez Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock {\em arXiv preprint arXiv:1505.05770}, 2015.

\bibitem{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{ranganath2014black}
Rajesh Ranganath, Sean Gerrish, and David Blei.
\newblock Black box variational inference.
\newblock In {\em Artificial Intelligence and Statistics}, pages 814--822,
  2014.

\bibitem{loaiza2017maximum}
Gabriel Loaiza-Ganem, Yuanjun Gao, and John~P Cunningham.
\newblock Maximum entropy flow networks.
\newblock {\em arXiv preprint arXiv:1701.03504}, 2017.

\bibitem{bittner2018learning}
Sean Bittner and John Cunningham.
\newblock Learning exponential families.
\newblock {\em (In review, AI Stats)}, ?(?):?--?, 2018.

\bibitem{sussillo2014neural}
David Sussillo.
\newblock Neural circuits as computational dynamical systems.
\newblock {\em Current opinion in neurobiology}, 25:156--163, 2014.

\bibitem{sussillo2013opening}
David Sussillo and Omri Barak.
\newblock Opening the black box: low-dimensional dynamics in high-dimensional
  recurrent neural networks.
\newblock {\em Neural computation}, 25(3):626--649, 2013.

\bibitem{werbos1990backpropagation}
Paul~J Werbos.
\newblock Backpropagation through time: what it does and how to do it.
\newblock {\em Proceedings of the IEEE}, 78(10):1550--1560, 1990.

\bibitem{sussillo2009generating}
David Sussillo and Larry~F Abbott.
\newblock Generating coherent patterns of activity from chaotic neural
  networks.
\newblock {\em Neuron}, 63(4):544--557, 2009.

\bibitem{martens2011learning}
James Martens and Ilya Sutskever.
\newblock Learning recurrent neural networks with hessian-free optimization.
\newblock In {\em Proceedings of the 28th International Conference on Machine
  Learning (ICML-11)}, pages 1033--1040. Citeseer, 2011.

\bibitem{depasquale2018full}
Brian DePasquale, Christopher~J Cueva, Kanaka Rajan, LF~Abbott, et~al.
\newblock full-force: A target-based method for training recurrent networks.
\newblock {\em PloS one}, 13(2):e0191527, 2018.

\bibitem{mastrogiuseppe2018linking}
Francesca Mastrogiuseppe and Srdjan Ostojic.
\newblock Linking connectivity, dynamics, and computations in low-rank
  recurrent neural networks.
\newblock {\em Neuron}, 99(3):609--623, 2018.

\bibitem{gelman2013philosophy}
Andrew Gelman and Cosma~Rohilla Shalizi.
\newblock Philosophy and the practice of bayesian statistics.
\newblock {\em British Journal of Mathematical and Statistical Psychology},
  66(1):8--38, 2013.

\bibitem{russo2018motor}
Abigail~A Russo, Sean~R Bittner, Sean~M Perkins, Jeffrey~S Seely, Brian~M
  London, Antonio~H Lara, Andrew Miri, Najja~J Marshall, Adam Kohn, Thomas~M
  Jessell, et~al.
\newblock Motor cortex embeds muscle-like commands in an untangled population
  response.
\newblock {\em Neuron}, 97(4):953--966, 2018.

\bibitem{dipoppa2018vision}
Mario Dipoppa, Adam Ranson, Michael Krumin, Marius Pachitariu, Matteo
  Carandini, and Kenneth~D Harris.
\newblock Vision and locomotion shape the interactions between neuron types in
  mouse visual cortex.
\newblock {\em Neuron}, 98(3):602--615, 2018.

\end{thebibliography}
