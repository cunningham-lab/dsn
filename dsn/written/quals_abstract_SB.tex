% You should title the file with a .tex extension (hw1.tex, for example)
\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{tikz-qtree}
\usepackage{tikz-qtree-compat}
\usepackage[normalem]{ulem}
\usepackage{tikz}
\usepackage{graphicx}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}

\oddsidemargin0cm
\topmargin-2cm     %I recommend adding these three lines to increase the 
\textwidth16.5cm   %amount of usable space on the page (and save trees)
\textheight23.5cm  

\newcommand{\question}[2] {\vspace{.25in} \hrule\vspace{0.5em}
\noindent{\bf #1: #2} \vspace{0.5em}
\hrule \vspace{.10in}}
\renewcommand{\part}[1] {\vspace{.10in} {\bf (#1)}}

\newcommand{\myname}{Sean Bittner}
\newcommand{\myandrew}{srb2201@columbia.edu}
\newcommand{\myhwnum}{12}

\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}
 
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
 
\pagestyle{fancyplain}
\rhead{\fancyplain{}{\myname\\ \myandrew}}

\begin{document}

\medskip                        % Skip a "medium" amount of space
                                % (latex determines what medium is)
                                % Also try: \bigskip, \littleskip

\thispagestyle{plain}
\begin{center}                  % Center the following lines
{\Large Degenerate solution networks (DSNs) for theoretical neuroscience} \\
Sean Bittner \\
Novemeber 8, 2018 \\
\end{center}

Theoretical neuroscientists have complemented experimental investigations in our field by designing and testing mathematical models of neural activity \cite{abbott2008theoretical}. Free of the burdens of experimental neuroscience, theorists do this with rapid turnover, frequently rejecting and sometimes promoting new models, which make accurate postdictions of established experiments.  A challenge in this scientific paradigm is the indeterminacy of model parameterizations; different parameterizations of these models yield accurate postdictions, but make disparate predictions.  Oftentimes, the parameter space of these models is characterized by extensive simulation with no probabilistic treatment of the solution space.  When both data and a reliable posterior inference method are available, probability can be assigned to each parameterization based on data likelihood and some prior assumptions.  Even in these cases, it is unclear how the structure of the posterior distribution relies on different properties of the data.  We propose a new machine learning methodology for learning probabilistic degenerate solution spaces of models given statistical descriptions of the model behavior.  The (Aim 1) development of degenerate solution networks (DSNs) will enable a novel methodology of hypothetico-deductive reasoning for (Aim 2) characterizing learning algorithm biases, (Aim 3) performing model comparison, and (Aim 4) informing model revision.

\textbf{Aim 1: Develop DSNs and assess scalability on classes of models and behaviors.} \\
DSN learn probabilistic degenerate solution spaces by making deep generative approximations to the maximally entropic distribution of model parameterizations that result in a model behavior of interest.  Consider model parameterization $z$ and data $x$ generated from the model of interest $p(x \mid z)$, where $z \sim q_{\theta}$ are samples from the DSN via a deterministic mapping parameterized by a neural network $f_\theta$ of a simple random variable $w \sim p_0$: \\
\begin{equation} z = f_{\theta}(w) \end{equation} 
 DSNs are trained by optimizing the deep generative parameters $\theta$ to find the optimal approximation $q_{\theta}^*$ within the deep generative variational family $Q$ to the degenerate solution space.  This is done by optimizing the following objective for a behavior of interest $ E\left[ T(x)\right] = \mu$:
\begin{equation}
\begin{split}
q_\theta^*(z) = & \argmax_{q_\theta \in Q} H(q_\theta(z)) \\
& \text{s.t.  } E_{z \sim q_\theta}\left[ E_{x\sim p(x \mid z)}\left[T(x)\right] \right] = \mu \\
\end{split}
\end{equation}
This procedure is equivalent to variational inference (VI) using a deep generative variational family with respect to the likelihood of the mean sufficient statistics rather than the data itself.  In most settings (especially those relevant to theoretical neuroscience) the likelihood of the behavior with respect to the model parameters $p(T(x) \mid z)$ will be intractable, requiring an alternative to stochastic gradient variational bayes (SGVB) \cite{kingma2013auto} or black box variational inference (BBVI) \cite{ranganath2014black}. As long as the desired behavior of the model can be statistically characterized as some expectation of sufficient statistics that are differentiable with respect to the model parameters $z$ (and therefore the deep generative parameters $\theta$), we can run the corresponding augmented LaGrangian procedure for the constrained maximum entropy optimization optimization \cite{loaiza2017maximum}.  A convenient property of maximum entropy optimizations is their exponential family form solutions, which yield a convenient diagnostic for assessing global maximum convergence. The tractability of this optimization will be assessed using this diagnostic with regard to a mixture of factors: dimensionality of the parameter space, the complexity of the model, and the behavior of interest.


\textbf{Aim 2: Learn solution spaces of dynamic computations.} \\
Recurrent neural networks (RNNs) are often trained to execute computations in order to perform some experimental task with the intention of comparing the trained system's activity with that measured in the brain \cite{sussillo2014neural}.  Statements about the particular algorithm or computational strategy implemented by the RNN are often made by analyzing linearized dynamics around fixed points \cite{sussillo2013opening}.  There are a variety of methods used to train RNNs \cite{werbos1990backpropagation, sussillo2009generating, martens2011learning, depasquale2018full}, and how these learning methods bias the learned connectivities (and potentially the implemented algorithm) within the broader solution space remains poorly understood.  Relying on recent work describing the statistical properties of low-rank RNNs \cite{mastrogiuseppe2018linking}, we can train DSNs to learn maximally expansive low dimensional distributions of parameterizations of network connectivities that solve tasks such as noisy stimulus detection, context-dependent discrimination, and evidence integration.  To check for a particular bias in a training method, we can formulate a structure-indicating test statistic that captures this bias.  Then, the distribution of this test statistic over randomness in the training procedure can be compared to its distribution in the full solution space obtained with DSNs.

This will be our first use of DSNs to generate maximally random distributions of test statistics under a model with a particular behavioral specification.  One can think of DSNs as a tool to obtain maximally entropic distributions of summary statistics of models given constraints on other statistics (i.e. the model behavior).  Here, we will use DSNs to test whether some learning algorithms bias RNN connectivity within the broader solution space. 

\textbf{Aim 3: Behavioral model comparison.} \\
Bayesian statistical analyses allow us to make inferences about the rules that govern the data we have and will have, which is commonly framed as inductive reasoning.  As Gelman and Shalizi remind us \cite{gelman2013philosophy}, model checking procedures comparing test statistics of the data and posterior-predictive distribution facilitate model rejection through hypothetico-deductive reasoning.  Akin to the idea of model-checking in Bayesian statistics, with DSNs, we can compare full distributions of a test statistics of models $\mathcal{M}_{p,\mathcal{B}}$ indexed by generative model $p$ and produced behavior $\mathcal{B}$ to the same model producing different behaviors (compare $\mathcal{M}_{p,\mathcal{B}_1}$ to $\mathcal{M}_{p,\mathcal{B}_2}$), another model producing the same behavior (compare $\mathcal{M}_{p_1,\mathcal{B}}$ to $\mathcal{M}_{p_2,\mathcal{B}}$), and a different model producing a different behavior (compare $\mathcal{M}_{p_1,\mathcal{B}_1}$ to $\mathcal{M}_{p_2,\mathcal{B}_2}$).  Critically, none of these enumerated types of model comparisons directly rely on collected data as is typical in traditional statistical thinking.  While the behaviors we are interested are likely motivated by data collected through experimentation, the data itself is unnecessary for executing a hypothesis test.  To demonstrate how powerful this methodology can be, we will use a single analysis facilitated by DSNs to make an affirmative statement about the relationship of noise robustness and tangling in RNNs, compared to several analyses which made a weaker statement in our previous work \cite{russo2018motor}.

\textbf{Aim 4: Behavioral model revision.} \\
Access to the full probabilistic degenerate solution space of a theoretical model that yields accurate postdictions can inform model revision in several ways.  Letâ€™s say we have behaviors $\mathcal{B}_1$ and $\mathcal{B}_2$ which are well established experimentally.  We have some model $p(x | z; \phi)$ with parameters $z$ and hyperparameters governing model selection $\phi$, which is capable of producing behaviors $\mathcal{B}_1$ and $\mathcal{B}_2$ independently.  We break down $\phi = \left[\phi_c, \phi_{nc} \right]$ into continuous and non-continuous sets of model-selection parameters, respectfully.  For example, $\phi_{nc}$ may govern some choice of model architecture.  If we learn a DSN for $\mathcal{M}_{p,\mathcal{B}_1}$ and find there is no support of $q_{\theta}^*(z)$ that yields $\mathcal{B}_2$, we effectively realize that our model is wrong.  Our first step for model revision can be to choose some subset of $\phi_{c,opt} \subseteq \phi_c$, and concatenate it to $z$ so that $\tilde{z} = [z, \phi_{c,opt}]$ with $\tilde{\phi} = \left[ \phi_{c,fixed}, \phi_{nc} \right]$, and learn a new DSN $\mathcal{M}_{\tilde{p}, \mathcal{B}_1}$ for generative model $\tilde{p}(x \mid \tilde{z}, \tilde{\phi})$.  Then, we can look for $\phi_{c,opt}$ that yield $\mathcal{B}_2$ indicating the necessary model revision.  Alternatively, insights from the probabilistic degenerate solution space can give theorists with specialty knowledge about $p(x | z; \phi)$ information on how to change $\phi$ in general.  We will demonstrate how probabilistic degenerate solution spaces of a V1 circuit model reproducing findings from \cite{dipoppa2018vision} can identify actions for model revision.

\bibliography{dsn}
\bibliographystyle{unsrt}

\end{document}

